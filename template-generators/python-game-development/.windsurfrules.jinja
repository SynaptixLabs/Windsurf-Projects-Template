# Project Local Rules for Windsurf - {{project_name}}

These rules supplement the Global Operating Rules and provide Python project development guidelines for assistants working on this project. They define the expected coding standards, patterns, and best practices for modern Python development.

---

## âš ï¸ CRITICAL: Project State Management

### ðŸ”„ State Tracking Requirements (MANDATORY)

**Windsurf MUST maintain project continuity by updating `state.md` after every significant milestone:**

1. **State Update Triggers** (Update `state.md` immediately after):
   - âœ… Completing any sprint (Sprint 0, 1, 2, 3)
   - âœ… Finishing major development milestones
   - âœ… Completing significant feature implementations
   - âœ… Before ending any development session
   - âœ… Major architectural decisions or refactoring

2. **State Update Format** (Required in `state.md`):
   ```markdown
   **Last Updated**: [CURRENT_DATE_TIME]
   **Current Sprint**: [SPRINT_NUMBER_AND_PHASE]
   **Current Phase**: [DETAILED_DESCRIPTION]
   **Progress**: [BRIEF_PROGRESS_SUMMARY]
   
   ## Development Summary
   [CONCISE_TEXT_SUMMARY_OF_COMPLETED_WORK]
   
   ## Sprint Status
   - **Sprint N**: [STATUS_EMOJI] [STATUS] - [BRIEF_DESCRIPTION]
   ```

3. **Session Continuation Protocol**:
   - **Always read `state.md` first** when returning to project
   - Provide brief summary of completed work and current objectives
   - Resume development from exact point indicated in state
   - **Never start from beginning** if state indicates progress

**This ensures seamless development continuation across Windsurf sessions!**

### ðŸš€ Project Initialization

**First Time Setup**: When user says:
```
I just generated this {{project_name}} project. Please run/execute the start-coding script in .commands/start-coding.md
```

**Execute**: Follow `.commands/start-coding.md` exactly for:
- Project structure review
- TODO assessment and creation
- Environment validation  
- State initialization
- Sprint 1 commencement

---

## General Rules

### ðŸ“Œ Important Project Rules
- **Documentation**: Always reference the primary project documentation (`docs/`) before beginning any task.
- **Sprint Management**: Follow the sprint-based TODO files for structured development.
- **Team Configuration**: Team members and their roles are outlined in the `.windsurf_config.yaml` file.
- **Quality First**: All code should prioritize maintainability, performance, and user experience.

### ðŸ Python Development Principles
1. **Type Safety**: Use type hints consistently and validate with MyPy
2. **Immutable Patterns**: Prefer immutable data structures and functional approaches where appropriate
3. **Clear Separation**: Separate business logic, data access, and presentation concerns
4. **Error Handling**: Use explicit error handling with custom exceptions
5. **Resource Management**: Properly manage resources with context managers and proper cleanup

---

## Development Stack Rules

**Stack:** Python {{python_version}}, {{game_framework}}, Pydantic, structlog

### I. Code Style & Conventions

1. **Naming Conventions:**
   ```python
   # Classes: PascalCase for entities
   class DataProcessor:
   class UserSession:
   class ConfigManager:
   
   # Functions: snake_case for actions
   def process_data(input_data: List[Dict]) -> ProcessedData:
   def validate_config() -> ValidationResult:
   def handle_user_input(user_input: str) -> Response:
   
   # Constants: UPPER_SNAKE_CASE
   MAX_RETRY_ATTEMPTS = 3
   DEFAULT_TIMEOUT = 30
   CONFIG_FILE_PATH = "config/settings.yaml"
   ```

2. **Data Models with Pydantic:**
   ```python
   # Use Pydantic for data validation and models
   from pydantic import BaseModel, Field, validator
   from typing import Optional, List
   from enum import Enum
   
   class Status(Enum):
       PENDING = "pending"
       PROCESSING = "processing"
       COMPLETED = "completed"
       FAILED = "failed"
   
   class ProcessingRequest(BaseModel):
       id: str = Field(..., description="Unique request identifier")
       data: Dict[str, Any] = Field(..., description="Input data to process")
       priority: int = Field(default=1, ge=1, le=10)
       status: Status = Status.PENDING
       
       @validator('id')
       def validate_id(cls, v):
           if not v or len(v) < 3:
               raise ValueError('ID must be at least 3 characters')
           return v
   ```

3. **Framework-Specific Patterns:**
   ```python
   # Example: Clean architecture patterns
   class ServiceManager:
       def __init__(self, config: AppConfig):
           self.config = config
           self.logger = structlog.get_logger(__name__)
       
       def process_request(self, request: ProcessingRequest) -> ProcessingResult:
           """Process request with proper error handling and logging."""
           self.logger.info(
               "Processing request",
               request_id=request.id,
               priority=request.priority
           )
           
           try:
               result = self._execute_processing(request)
               self.logger.info("Request completed", request_id=request.id)
               return result
           except ProcessingError as e:
               self.logger.error(
                   "Processing failed",
                   request_id=request.id,
                   error=str(e)
               )
               raise
   ```

### II. Architecture Patterns

1. **Application Structure:**
   ```python
   # Example: Clean separation of concerns
   class ApplicationCore:
       def __init__(self, settings: AppSettings):
           self.settings = settings
           self.logger = structlog.get_logger(__name__)
           self.services = self._initialize_services()
       
       def run(self) -> None:
           """Main application loop with proper lifecycle management."""
           try:
               self._startup()
               self._main_loop()
           except KeyboardInterrupt:
               self.logger.info("Shutdown requested")
           finally:
               self._cleanup()
       
       def _startup(self) -> None:
           """Initialize resources and validate configuration."""
           self.logger.info("Starting application")
           self.settings.validate()
           
       def _main_loop(self) -> None:
           """Main processing loop - implement based on application needs."""
           pass
           
       def _cleanup(self) -> None:
           """Clean up resources."""
           self.logger.info("Application shutdown complete")
   ```

2. **Dependency Injection Pattern:**
   ```python
   # Example: Constructor injection for testability
   from abc import ABC, abstractmethod
   
   class DataRepository(ABC):
       @abstractmethod
       async def save(self, data: ProcessedData) -> str:
           pass
   
   class ProcessingService:
       def __init__(self, repository: DataRepository, logger: structlog.Logger):
           self.repository = repository
           self.logger = logger
       
       async def process_and_save(self, input_data: RawData) -> str:
           processed = self._process(input_data)
           saved_id = await self.repository.save(processed)
           self.logger.info("Data processed and saved", saved_id=saved_id)
           return saved_id
   ```

3. **Error Handling Patterns:**
   ```python
   # Use custom exceptions for domain-specific errors
   from core.exceptions import ValidationError, ProcessingError
   
   class DataProcessor:
       def process(self, data: RawData) -> ProcessedData:
           if not self._validate_input(data):
               raise ValidationError(f"Invalid input data: {data}")
           
           try:
               return self._transform_data(data)
           except Exception as e:
               raise ProcessingError(f"Processing failed: {e}") from e
   ```

### III. Performance Guidelines

1. **Efficient Data Processing:**
   ```python
   # Example: Memory-efficient processing
   from typing import Iterator
   import asyncio
   
   class DataStreamProcessor:
       def __init__(self, batch_size: int = 1000):
           self.batch_size = batch_size
       
       def process_stream(self, data_stream: Iterator[RawData]) -> Iterator[ProcessedData]:
           """Process data in batches to manage memory usage."""
           batch = []
           for item in data_stream:
               batch.append(item)
               if len(batch) >= self.batch_size:
                   yield from self._process_batch(batch)
                   batch = []
           
           # Process remaining items
           if batch:
               yield from self._process_batch(batch)
   
   # Async patterns for I/O-bound operations
   async def fetch_and_process_data(urls: List[str]) -> List[ProcessedData]:
       """Concurrent processing for better performance."""
       async with aiohttp.ClientSession() as session:
           tasks = [fetch_url(session, url) for url in urls]
           raw_data = await asyncio.gather(*tasks)
           return [process_data(data) for data in raw_data]
   ```

2. **Caching Strategies:**
   ```python
   # Example: Smart caching for expensive operations
   from functools import lru_cache
   from typing import Optional
   import time
   
   class CachedProcessor:
       def __init__(self, cache_ttl: int = 300):
           self.cache_ttl = cache_ttl
           self._cache = {}
       
       @lru_cache(maxsize=1000)
       def expensive_calculation(self, input_value: str) -> float:
           """Cache expensive calculations."""
           # Simulate expensive operation
           time.sleep(0.1)
           return hash(input_value) / 1000000
       
       def get_with_ttl(self, key: str) -> Optional[Any]:
           """Simple TTL cache implementation."""
           if key in self._cache:
               data, timestamp = self._cache[key]
               if time.time() - timestamp < self.cache_ttl:
                   return data
               del self._cache[key]
           return None
   ```

### IV. Testing Patterns

1. **Comprehensive Testing Strategy:**
   ```python
   # Example: Unit testing with fixtures
   import pytest
   from unittest.mock import Mock, patch
   
   class TestDataProcessor:
       @pytest.fixture
       def processor(self):
           return DataProcessor(config=test_config)
       
       @pytest.fixture
       def sample_data(self):
           return ProcessingRequest(
               id="test-123",
               data={"value": 42},
               priority=1
           )
       
       def test_successful_processing(self, processor, sample_data):
           result = processor.process(sample_data)
           assert result.status == Status.COMPLETED
           assert result.output is not None
       
       @patch('external_service.api_call')
       def test_external_service_integration(self, mock_api, processor):
           mock_api.return_value = {"status": "success"}
           result = processor.process_with_external_service(sample_data)
           assert result.success is True
           mock_api.assert_called_once()
   ```

2. **Property-Based Testing:**
   ```python
   # Example: Using Hypothesis for robust testing
   from hypothesis import given, strategies as st, assume
   
   class TestValidation:
       @given(st.text(min_size=1, max_size=100))
       def test_valid_input_never_raises_exception(self, input_text):
           processor = DataProcessor()
           assume(processor.is_valid_input(input_text))
           
           # Should never raise for valid inputs
           result = processor.process_text(input_text)
           assert result is not None
       
       @given(st.integers(min_value=1, max_value=10))
       def test_priority_handling(self, priority):
           request = ProcessingRequest(
               id="test",
               data={},
               priority=priority
           )
           assert 1 <= request.priority <= 10
   ```

### V. Configuration & Settings

1. **Use Pydantic for Settings:**
   ```python
   # All settings in config/app_settings.py
   from pydantic import BaseSettings, Field, validator
   from typing import Optional
   
   class AppSettings(BaseSettings):
       app_name: str = Field(default="{{project_name}}", description="Application name")
       debug: bool = Field(default=False, description="Debug mode")
       log_level: str = Field(default="INFO", description="Logging level")
       max_workers: int = Field(default=4, gt=0, le=32)
       database_url: Optional[str] = Field(default=None, description="Database connection URL")
       
       @validator('log_level')
       def validate_log_level(cls, v):
           valid_levels = ['DEBUG', 'INFO', 'WARNING', 'ERROR', 'CRITICAL']
           if v.upper() not in valid_levels:
               raise ValueError(f'Log level must be one of {valid_levels}')
           return v.upper()
       
       class Config:
           env_file = ".env"
           env_prefix = "{{project_name.upper().replace('-', '_')}}_"
   ```

2. **Structured Logging:**
   ```python
   import structlog
   from config.app_settings import settings
   
   # Configure structured logging
   structlog.configure(
       processors=[
           structlog.processors.TimeStamper(fmt="iso"),
           structlog.processors.add_log_level,
           structlog.processors.JSONRenderer()
       ],
       logger_factory=structlog.PrintLoggerFactory(),
       wrapper_class=structlog.make_filtering_bound_logger(
           getattr(logging, settings.log_level)
       ),
   )
   
   logger = structlog.get_logger(__name__)
   
   def process_data(data: Dict[str, Any]) -> ProcessingResult:
       logger.info(
           "Processing started",
           data_size=len(data),
           data_type=type(data).__name__
       )
       # Processing logic here
       logger.info("Processing completed successfully")
   ```

---

## Quality Standards

### Code Quality Requirements
- **Test Coverage**: >85% for business logic, >70% for integration code
- **Type Coverage**: >90% type annotation coverage (validated with MyPy)
- **Performance**: Meet defined performance benchmarks
- **Memory**: No memory leaks during extended operation
- **Compatibility**: Support Python {{python_version}}+ and all specified dependencies

### Development Workflow
1. **TDD Approach**: Write tests for business logic before implementation
2. **Frequent Commits**: Commit working features frequently with clear messages
3. **Code Reviews**: All changes require review focusing on maintainability and correctness
4. **Performance Monitoring**: Profile application performance before sprint completion

### Documentation Requirements
- **Docstrings**: All public functions and classes must have comprehensive docstrings
- **Architecture Docs**: Update `docs/architecture.md` when adding new systems
- **API Documentation**: Document all public interfaces and their contracts
- **Performance Notes**: Document performance considerations and optimization strategies

---

**Framework**: {{game_framework}}  
**Target Platform**: Cross-platform Python  
**Performance Target**: Meet defined SLA requirements  
**Code Style**: Ruff + MyPy strict mode